{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1d36e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import date\n",
    "import os\n",
    "from pyspark.sql.functions import col, explode,monotonically_increasing_id\n",
    "\n",
    "spark = SparkSession.builder.appName('pract').getOrCreate()\n",
    "df_pyspark = spark.read.json('MPE1004.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3e7e9a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 col|\n",
      "+--------------------+\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0NBT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "|{true, {TVBFQ0NBT...|\n",
      "|{true, {TVBFQ0xJT...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_pyspark.select(explode(col('results')))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e3a5b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.withColumn('RowId', monotonically_increasing_id() + 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "21d3510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('RowId', monotonically_increasing_id() + 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d2cc6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.selectExpr('RowId','col.id as itemId','col.sold_quantity','col.available_quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "962999bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df = spark.read.option('header',True).csv('visits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bf495ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|visits|      itemId|\n",
      "+------+------------+\n",
      "|   203|MPE433108265|\n",
      "|   170|MPE434382765|\n",
      "|  1034|MPE433853177|\n",
      "|  1772|MPE419883282|\n",
      "|    33|MPE431714651|\n",
      "|  1160|MPE438492919|\n",
      "|  2669|MPE429448587|\n",
      "|    36|MPE439307195|\n",
      "|   257|MPE439307251|\n",
      "|   292|MPE437503507|\n",
      "|   102|MPE438828260|\n",
      "|    29|MPE439307426|\n",
      "|    50|MPE440306037|\n",
      "|   120|MPE439307206|\n",
      "|  2242|MPE431446248|\n",
      "|   108|MPE439307250|\n",
      "|    56|MPE439510012|\n",
      "|   183|MPE439307317|\n",
      "|   267|MPE439307286|\n",
      "|    22|MPE439307385|\n",
      "+------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#uter', 'leftouter', 'left', 'left_outer', 'rightouter', 'right', 'right_outer', 'leftsemi', 'left_semi', 'semi', 'leftanti', 'left_anti', 'anti', 'cross'.\n",
    "visits_df.select('visits', 'itemId').show()\n",
    "\n",
    "#visits_df.join(df,visits_df.itemId == df.itemId,\n",
    "#              \"right_outer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "69aafa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rigth_df = df.select('RowId','sold_quantity','available_quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "743c960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(visits_df,visits_df.itemId == df.itemId).select(df[\"*\"],visits_df['visits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd694b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b98522e",
   "metadata": {},
   "source": [
    "  (Conversiones u objetivos alcanzados / Total de usuarios) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "81379aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"conversionRate\", round(col('sold_quantity')/col('visits'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f56e22c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad76bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a1855996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "windowSpec  = Window.orderBy(col(\"conversionRate\").desc())\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "34a81400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"conversionRank\", rank().over(windowSpec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b4b00bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/13 01:20:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/06/13 01:20:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/06/13 01:20:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+-------------+------------------+------+--------------+--------------+\n",
      "|RowId|      itemId|sold_quantity|available_quantity|visits|conversionRate|conversionRank|\n",
      "+-----+------------+-------------+------------------+------+--------------+--------------+\n",
      "|    5|MPE431714651|           15|                 1|    33|        0.4545|             1|\n",
      "|   34|MPE432291284|            2|                 1|     6|        0.3333|             2|\n",
      "|   38|MPE427140390|           10|                 2|    81|        0.1235|             3|\n",
      "|   26|MPE432439269|            2|                 1|    42|        0.0476|             4|\n",
      "|    2|MPE434382765|            6|                 3|   170|        0.0353|             5|\n",
      "|    1|MPE433108265|            6|                 9|   203|        0.0296|             6|\n",
      "|   36|MPE433252062|            2|                 1|    92|        0.0217|             7|\n",
      "|   33|MPE433933924|            1|                 1|    49|        0.0204|             8|\n",
      "|   28|MPE430002527|            1|                 1|    60|        0.0167|             9|\n",
      "|   35|MPE432728801|            1|                 1|    68|        0.0147|            10|\n",
      "|    4|MPE419883282|           15|                18|  1772|        0.0085|            11|\n",
      "|   23|MPE440389411|            1|                 9|   158|        0.0063|            12|\n",
      "|   24|MPE421767433|            4|                11|   746|        0.0054|            13|\n",
      "|    3|MPE433853177|            3|                17|  1034|        0.0029|            14|\n",
      "|   32|MPE428549082|            1|                 4|   352|        0.0028|            15|\n",
      "|   22|MPE432990777|            1|                 5|   426|        0.0023|            16|\n",
      "|   15|MPE431446248|            2|                23|  2242|        9.0E-4|            17|\n",
      "+-----+------------+-------------+------------------+------+--------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/13 01:20:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "df.select('*').where(col('conversionRate')> 0.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b0622e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('stockPercentage', (col('available_quantity')*100)/(col('sold_quantity')+col('available_quantity')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "42cbbb02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+------------------+\n",
      "|      ItemId|available_quantity|   stockPercentage|\n",
      "+------------+------------------+------------------+\n",
      "|MPE433108265|                 9|              60.0|\n",
      "|MPE434382765|                 3|33.333333333333336|\n",
      "|MPE433853177|                17|              85.0|\n",
      "|MPE419883282|                18| 54.54545454545455|\n",
      "|MPE431714651|                 1|              6.25|\n",
      "|MPE438492919|               100|             100.0|\n",
      "|MPE429448587|                50|             100.0|\n",
      "|MPE439307195|                 3|             100.0|\n",
      "|MPE439307251|                 3|             100.0|\n",
      "|MPE437503507|                10|             100.0|\n",
      "|MPE438828260|                 3|             100.0|\n",
      "|MPE439307426|                 3|             100.0|\n",
      "|MPE440306037|                 1|             100.0|\n",
      "|MPE439307206|                 3|             100.0|\n",
      "|MPE431446248|                23|              92.0|\n",
      "|MPE439307250|                 3|             100.0|\n",
      "|MPE439510012|                 1|             100.0|\n",
      "|MPE439307317|                 3|             100.0|\n",
      "|MPE439307286|                 3|             100.0|\n",
      "|MPE439307385|                 3|             100.0|\n",
      "|MPE440131689|                 7|             100.0|\n",
      "|MPE432990777|                 5| 83.33333333333333|\n",
      "|MPE440389411|                 9|              90.0|\n",
      "|MPE421767433|                11| 73.33333333333333|\n",
      "|MPE432990779|                 1|             100.0|\n",
      "|MPE432439269|                 1|33.333333333333336|\n",
      "|MPE431410374|                 1|             100.0|\n",
      "|MPE430002527|                 1|              50.0|\n",
      "|MPE432990781|                 1|             100.0|\n",
      "|MPE432202936|                10|             100.0|\n",
      "|MPE428549066|                 5|             100.0|\n",
      "|MPE428549082|                 4|              80.0|\n",
      "|MPE433933924|                 1|              50.0|\n",
      "|MPE432291284|                 1|33.333333333333336|\n",
      "|MPE432728801|                 1|              50.0|\n",
      "|MPE433252062|                 1|33.333333333333336|\n",
      "|MPE436649728|               100|             100.0|\n",
      "|MPE427140390|                 2|16.666666666666668|\n",
      "|MPE433046443|               999|             100.0|\n",
      "+------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('ItemId','available_quantity','stockPercentage').show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fadd2563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+-------------+------------------+------+\n",
      "|RowId|      itemId|sold_quantity|available_quantity|visits|\n",
      "+-----+------------+-------------+------------------+------+\n",
      "|    1|MPE433108265|            6|                 9|   203|\n",
      "|    2|MPE434382765|            6|                 3|   170|\n",
      "|    3|MPE433853177|            3|                17|  1034|\n",
      "|    4|MPE419883282|           15|                18|  1772|\n",
      "|    5|MPE431714651|           15|                 1|    33|\n",
      "|    6|MPE438492919|            0|               100|  1160|\n",
      "|    7|MPE429448587|            0|                50|  2669|\n",
      "|    8|MPE439307195|            0|                 3|    36|\n",
      "|    9|MPE439307251|            0|                 3|   257|\n",
      "|   10|MPE437503507|            0|                10|   292|\n",
      "|   11|MPE438828260|            0|                 3|   102|\n",
      "|   12|MPE439307426|            0|                 3|    29|\n",
      "|   13|MPE440306037|            0|                 1|    50|\n",
      "|   14|MPE439307206|            0|                 3|   120|\n",
      "|   15|MPE431446248|            2|                23|  2242|\n",
      "|   16|MPE439307250|            0|                 3|   108|\n",
      "|   17|MPE439510012|            0|                 1|    56|\n",
      "|   18|MPE439307317|            0|                 3|   183|\n",
      "|   19|MPE439307286|            0|                 3|   267|\n",
      "|   20|MPE439307385|            0|                 3|    22|\n",
      "+-----+------------+-------------+------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import date\n",
    "import os\n",
    "from pyspark.sql.functions import col, explode,monotonically_increasing_id\n",
    "\n",
    "spark = SparkSession.builder.appName('pract').getOrCreate()\n",
    "df_pyspark = spark.read.json('MPE1004.json')\n",
    "df = df_pyspark.select(explode(col('results')))\n",
    "df = df.withColumn('RowId', monotonically_increasing_id() + 1 )\n",
    "df = df.selectExpr('RowId','col.id as itemId','col.sold_quantity','col.available_quantity')\n",
    "visits_df = spark.read.option('header',True).csv('visits.csv')\n",
    "rigth_df = df.select('RowId','sold_quantity','available_quantity')\n",
    "df = df.join(visits_df,visits_df.itemId == df.itemId).select(df[\"*\"],visits_df['visits']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3070b73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/13 01:16:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/06/13 01:16:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/06/13 01:16:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+-------------+------------------+------+--------------+--------------+\n",
      "|RowId|      itemId|sold_quantity|available_quantity|visits|conversionRate|conversionRank|\n",
      "+-----+------------+-------------+------------------+------+--------------+--------------+\n",
      "|    5|MPE431714651|           15|                 1|    33|        0.4545|             1|\n",
      "|   34|MPE432291284|            2|                 1|     6|        0.3333|             2|\n",
      "|   38|MPE427140390|           10|                 2|    81|        0.1235|             3|\n",
      "|   26|MPE432439269|            2|                 1|    42|        0.0476|             4|\n",
      "|    2|MPE434382765|            6|                 3|   170|        0.0353|             5|\n",
      "|    1|MPE433108265|            6|                 9|   203|        0.0296|             6|\n",
      "|   36|MPE433252062|            2|                 1|    92|        0.0217|             7|\n",
      "|   33|MPE433933924|            1|                 1|    49|        0.0204|             8|\n",
      "|   28|MPE430002527|            1|                 1|    60|        0.0167|             9|\n",
      "|   35|MPE432728801|            1|                 1|    68|        0.0147|            10|\n",
      "|    4|MPE419883282|           15|                18|  1772|        0.0085|            11|\n",
      "|   23|MPE440389411|            1|                 9|   158|        0.0063|            12|\n",
      "|   24|MPE421767433|            4|                11|   746|        0.0054|            13|\n",
      "|    3|MPE433853177|            3|                17|  1034|        0.0029|            14|\n",
      "|   32|MPE428549082|            1|                 4|   352|        0.0028|            15|\n",
      "|   22|MPE432990777|            1|                 5|   426|        0.0023|            16|\n",
      "|   15|MPE431446248|            2|                23|  2242|        9.0E-4|            17|\n",
      "+-----+------------+-------------+------------------+------+--------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/13 01:16:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import date\n",
    "import os\n",
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, explode,monotonically_increasing_id\n",
    "\n",
    "spark = SparkSession.builder.appName('pract').getOrCreate()\n",
    "df_pyspark = spark.read.json('MPE1004.json')\n",
    "df = df_pyspark.select(explode(col('results')))\n",
    "df = df.withColumn('RowId', monotonically_increasing_id() + 1 )\n",
    "df = df.selectExpr('RowId','col.id as itemId','col.sold_quantity','col.available_quantity')\n",
    "visits_df = spark.read.option('header',True).csv('visits.csv')\n",
    "rigth_df = df.select('RowId','sold_quantity','available_quantity')\n",
    "df = df.join(visits_df,visits_df.itemId == df.itemId).select(df[\"*\"],visits_df['visits'])\n",
    "windowSpec  = Window.orderBy(col(\"conversionRate\").desc())\n",
    "df = df.withColumn(\"conversionRate\", round(col('sold_quantity')/col('visits'),4))\n",
    "df = df.withColumn(\"conversionRank\", rank().over(windowSpec))\n",
    "df.select('*').where(col('conversionRate')> 0.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9b85304e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'id' given input columns: [RowId, available_quantity, itemId, sold_quantity, stockPercentage, visits];\n'Project ['id, available_quantity#2889L, stockPercentage#2934]\n+- Project [RowId#2883L, itemId#2886, sold_quantity#2888L, available_quantity#2889L, visits#2911, (cast((available_quantity#2889L * cast(100 as bigint)) as double) / cast((sold_quantity#2888L + available_quantity#2889L) as double)) AS stockPercentage#2934]\n   +- Project [RowId#2883L, itemId#2886, sold_quantity#2888L, available_quantity#2889L, visits#2911]\n      +- Join Inner, (itemId#2910 = itemId#2886)\n         :- Project [RowId#2883L, col#2881.id AS itemId#2886, col#2881.sold_quantity AS sold_quantity#2888L, col#2881.available_quantity AS available_quantity#2889L]\n         :  +- Project [col#2881, (monotonically_increasing_id() + cast(1 as bigint)) AS RowId#2883L]\n         :     +- Project [col#2881]\n         :        +- Generate explode(results#2868), false, [col#2881]\n         :           +- Relation [available_filters#2863,available_sorts#2864,filters#2865,paging#2866,related_results#2867,results#2868,secondary_results#2869,site_id#2870,sort#2871] json\n         +- Relation [itemId#2910,visits#2911] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [140]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mjoin(visits_df,visits_df\u001b[38;5;241m.\u001b[39mitemId \u001b[38;5;241m==\u001b[39m df\u001b[38;5;241m.\u001b[39mitemId)\u001b[38;5;241m.\u001b[39mselect(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m],visits_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisits\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstockPercentage\u001b[39m\u001b[38;5;124m'\u001b[39m, (col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable_quantity\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m/\u001b[39m(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msold_quantity\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m+\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable_quantity\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m---> 17\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavailable_quantity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstockPercentage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:1685\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols):\n\u001b[1;32m   1665\u001b[0m     \u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \n\u001b[1;32m   1667\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1685\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'id' given input columns: [RowId, available_quantity, itemId, sold_quantity, stockPercentage, visits];\n'Project ['id, available_quantity#2889L, stockPercentage#2934]\n+- Project [RowId#2883L, itemId#2886, sold_quantity#2888L, available_quantity#2889L, visits#2911, (cast((available_quantity#2889L * cast(100 as bigint)) as double) / cast((sold_quantity#2888L + available_quantity#2889L) as double)) AS stockPercentage#2934]\n   +- Project [RowId#2883L, itemId#2886, sold_quantity#2888L, available_quantity#2889L, visits#2911]\n      +- Join Inner, (itemId#2910 = itemId#2886)\n         :- Project [RowId#2883L, col#2881.id AS itemId#2886, col#2881.sold_quantity AS sold_quantity#2888L, col#2881.available_quantity AS available_quantity#2889L]\n         :  +- Project [col#2881, (monotonically_increasing_id() + cast(1 as bigint)) AS RowId#2883L]\n         :     +- Project [col#2881]\n         :        +- Generate explode(results#2868), false, [col#2881]\n         :           +- Relation [available_filters#2863,available_sorts#2864,filters#2865,paging#2866,related_results#2867,results#2868,secondary_results#2869,site_id#2870,sort#2871] json\n         +- Relation [itemId#2910,visits#2911] csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import date\n",
    "import os\n",
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, explode,monotonically_increasing_id\n",
    "\n",
    "spark = SparkSession.builder.appName('pract').getOrCreate()\n",
    "df_pyspark = spark.read.json('MPE1004.json')\n",
    "df = df_pyspark.select(explode(col('results')))\n",
    "df = df.withColumn('RowId', monotonically_increasing_id() + 1 )\n",
    "df = df.selectExpr('RowId','col.id as itemId','col.sold_quantity','col.available_quantity')\n",
    "visits_df = spark.read.option('header',True).csv('visits.csv')\n",
    "rigth_df = df.select('RowId','sold_quantity','available_quantity')\n",
    "df = df.join(visits_df,visits_df.itemId == df.itemId).select(df[\"*\"],visits_df['visits'])\n",
    "df = df.withColumn('stockPercentage', (col('available_quantity')*100)/(col('sold_quantity')+col('available_quantity')))\n",
    "df.select('id','available_quantity','stockPercentage').show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "25009e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+------------------+\n",
      "|      ItemId|available_quantity|   stockPercentage|\n",
      "+------------+------------------+------------------+\n",
      "|MPE433108265|                 9|              60.0|\n",
      "|MPE434382765|                 3|33.333333333333336|\n",
      "|MPE433853177|                17|              85.0|\n",
      "|MPE419883282|                18| 54.54545454545455|\n",
      "|MPE431714651|                 1|              6.25|\n",
      "|MPE438492919|               100|             100.0|\n",
      "|MPE429448587|                50|             100.0|\n",
      "|MPE439307195|                 3|             100.0|\n",
      "|MPE439307251|                 3|             100.0|\n",
      "|MPE437503507|                10|             100.0|\n",
      "|MPE438828260|                 3|             100.0|\n",
      "|MPE439307426|                 3|             100.0|\n",
      "|MPE440306037|                 1|             100.0|\n",
      "|MPE439307206|                 3|             100.0|\n",
      "|MPE431446248|                23|              92.0|\n",
      "|MPE439307250|                 3|             100.0|\n",
      "|MPE439510012|                 1|             100.0|\n",
      "|MPE439307317|                 3|             100.0|\n",
      "|MPE439307286|                 3|             100.0|\n",
      "|MPE439307385|                 3|             100.0|\n",
      "|MPE440131689|                 7|             100.0|\n",
      "|MPE432990777|                 5| 83.33333333333333|\n",
      "|MPE440389411|                 9|              90.0|\n",
      "|MPE421767433|                11| 73.33333333333333|\n",
      "|MPE432990779|                 1|             100.0|\n",
      "|MPE432439269|                 1|33.333333333333336|\n",
      "|MPE431410374|                 1|             100.0|\n",
      "|MPE430002527|                 1|              50.0|\n",
      "|MPE432990781|                 1|             100.0|\n",
      "|MPE432202936|                10|             100.0|\n",
      "|MPE428549066|                 5|             100.0|\n",
      "|MPE428549082|                 4|              80.0|\n",
      "|MPE433933924|                 1|              50.0|\n",
      "|MPE432291284|                 1|33.333333333333336|\n",
      "|MPE432728801|                 1|              50.0|\n",
      "|MPE433252062|                 1|33.333333333333336|\n",
      "|MPE436649728|               100|             100.0|\n",
      "|MPE427140390|                 2|16.666666666666668|\n",
      "|MPE433046443|               999|             100.0|\n",
      "+------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import date\n",
    "import os\n",
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, explode,monotonically_increasing_id\n",
    "\n",
    "spark = SparkSession.builder.appName('pract').getOrCreate()\n",
    "df_pyspark = spark.read.json('MPE1004.json')\n",
    "df = df_pyspark.select(explode(col('results')))\n",
    "df = df.withColumn('RowId', monotonically_increasing_id() + 1 )\n",
    "df = df.selectExpr('RowId','col.id as itemId','col.sold_quantity','col.available_quantity')\n",
    "visits_df = spark.read.option('header',True).csv('visits.csv')\n",
    "rigth_df = df.select('RowId','sold_quantity','available_quantity')\n",
    "df = df.join(visits_df,visits_df.itemId == df.itemId).select(df[\"*\"],visits_df['visits'])\n",
    "df = df.withColumn('stockPercentage', (col('available_quantity')*100)/(col('sold_quantity')+col('available_quantity')))\n",
    "df.select('ItemId','available_quantity','stockPercentage').show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4952d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
